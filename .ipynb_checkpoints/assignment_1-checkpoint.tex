\documentclass[a4paper, 11pt]{article}
\usepackage{inhofirst}
\lstset{language=python}
\lstset{label={lst:code_direct}}
\lstset{basicstyle=\footnotesize}


\title{Assignment 1}
\author{2015313254 노인호}
\date{September 29th 2019}


\begin{document}
\maketitle
\setstretch{0.7}
\setlength{\parskip}{0.05em}

\section{Progress}
\subsection{Problem}
붓꽃(Iris)의 품종을 분류하기 위한 문제이다. 붓꽃의 품종은 setosa, versicolor, virginica로 나눠지는데 어떤 품종인지 구분하기 위해 꽃받침(sepal)의 길이(length)와 너비(width), 그리고 꽃잎(petal)의 길이(length)와 너비(width)를 이용한다. 길이와 폭의 단위는 cm이다. 품종의 개수가 3개이고 각 품종에 대한 정보를 미리 알고 있으므로 multi-class classfication문제라는 것을 알 수 있고, supervised learning을 이용해서 학습을 진행한다.

\subsection{Data Load}

scikit-learn에 있는 iris데이터를 'load\_iris()'를 이용하여 로드하고 데이터의 형태를 파악한다. Target이 3개, Feature가 4개, 데이터는 총 150개가 numpy.ndarray의 형태로 저장이 되어있음을 확인할 수 있다.

\subsection{Data preprocessing}
\benum
\item iris data를 학습시키기 위한 입력변수와 종속변수는 다음과 같게 된다.
\bitem
	\item input variables(x) :  sepal length, sepal width, petal length, petal width
	\item output variables(y) : species (setosa, versicolor, virginica)
\eitem
\item scikit-learn의 train\_test\_split함수를 이용해서 먼저 train(train and valid)과 test set을 8:2로 나누고 validation을 위해 train(train and valid) set을 train과 valid set으로 8:2로 나눈다. random\_state=0으로 두었다.
\\
그래서 data set의 비율은 train : valid : test = 0.64 : 0.16 : 0.2 가 된다.

\item data scaling은 데이터를 정규화 시켜주는 StandardScaler함수를 사용하였다.
\eenum
\subsection{Learning Algorithm(KNN)}
Scikit-learn의 KNeighborsClassifier 함수를 사용하였다. main hyperparameter는 다음과 같다.
\bitem
	\item n\_neighbor (the number of neighbors k)
	\item metric (distance metric p : Euclidean(p=2), Manhattan(p=1). Minkowski(p=p) ... )
	\item weights (weighting scheme : uniform, distance(inverse of Euclidean, Manhattan. Minkowski ... ))
\eitem

\subsection{Hyperparameter}
n\_neighbor 값을 1-30개 까지 바꾸고, 5가지의 metric과 2개의 weights를 변경시켜가며 valid accuracy값이 제일 잘 나오는 Hyperparameter값을 찾았다. 
valid accuracy가 가장 높게 나오는 sweetspot은 n\_neighbors가 22였고 metric='minkowski' p가 3, weights='uniform', valid accuracy=1 였다.
\section{Conclusion}
1.6에서 나온 hyperparameter로 계산해본 test accuracy=0.9가 나왔다.

%\newpage
\section{Python code in jupyter notebook}

웹사이트 https://nbviewer.jupyter.org/ 에서 다음의 gist 주소를 입력하면

\bitem
	\item  https://gist.github.com/nosy0411/9d3e2a1c029c8f3eb7439a52ec01cacb
\eitem

assignment1.ipynb 파일과 assignment1.py 파일의 코드를 볼 수 있다.

\begin{comment}
\begin{lstlisting}
# 1.3 Data load

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
iris_dataset = load_iris()

print("Target names:", iris_dataset[`target_names'])
print("Feature names:\n", iris_dataset['feature_names'])
print("Type of data:", type(iris_dataset['data']))
print("Shape of data:", iris_dataset['data'].shape)
print("=============================")
print("Type of target:", type(iris_dataset['target']))
print("Shape of target:", iris_dataset['target'].shape)

# 1.4 Data preprocessing

X_train_and_valid, X_test, y_train_and_valid, y_test = train_test_split(
iris_dataset['data'], iris_dataset['target'], test_size=0.2, random_state=0)
print("X_train_and_valid shape:", X_train_and_valid.shape)
print("y_train_and_valid shape:", y_train_and_valid.shape)
print("=============================")
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

X_train, X_valid, y_train, y_valid = train_test_split(
X_train_and_valid, y_train_and_valid, test_size=0.2, random_state=0)
print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("=============================")
print("X_valid shape:", X_valid.shape)
print("y_valid shape:", y_valid.shape)

from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
scaler.fit(X_train)
X_train_scale=scaler.transform(X_train)
X_valid_scale=scaler.transform(X_valid)
X_test_scale=scaler.transform(X_test)

# 1.5 KNN and select hyperparameter

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

neighbors_settings = list(range(1, 31))
p_settings = list(range(1,6))
data_dict=dict()

def weight_func(weight):
p_dict=dict()
for p in p_settings:
training_accuracy=[]
valid_accuracy=[]
for n_neighbors in neighbors_settings:
# build the model
knn = KNeighborsClassifier(n_neighbors=n_neighbors, metric='minkowski', p=p, weights=weight)
knn.fit(X_train_scale, y_train)

y_train_hat = knn.predict(X_train_scale)
training_accuracy.append(accuracy_score(y_train, y_train_hat))

y_valid_hat = knn.predict(X_valid_scale)
valid_accuracy.append(accuracy_score(y_valid, y_valid_hat))
p_dict[p]=dict(training=training_accuracy, valid=valid_accuracy)
data_dict[weight]=p_dict

weight_func('uniform')
weight_func('distance')

data_dict

print(data_dict['uniform'][1]['training'][1])

import pandas as pd

data=dict()

for p in p_settings:
for n_neighbors in neighbors_settings:
if data.get('weights'):
data['weights'].append('uniform')
data['metric'].append(p)
data['k'].append(n_neighbors)
data['training_accuracy'].append(data_dict['uniform'][p]['training'][n_neighbors-1])
data['valid_accuracy'].append(data_dict['uniform'][p]['valid'][n_neighbors-1])
else:
data['weights']=['uniform']
data['metric']=[p]
data['k']=[n_neighbors]
data['training_accuracy']=[data_dict['uniform'][p]['training'][n_neighbors-1]]
data['valid_accuracy']=[data_dict['uniform'][p]['valid'][n_neighbors-1]]

for p in p_settings:
for n_neighbors in neighbors_settings:
data['weights'].append('distance')
data['metric'].append(p)
data['k'].append(n_neighbors)
data['training_accuracy'].append(data_dict['distance'][p]['training'][n_neighbors-1])
data['valid_accuracy'].append(data_dict['distance'][p]['valid'][n_neighbors-1])

df=pd.DataFrame(data, index=list(range(0,len(neighbors_settings)*len(p_settings)*2)), columns=['weights','metric','k','training_accuracy','valid_accuracy'])
df

m=df['valid_accuracy'].max()
max_index=[i for i, j in enumerate(list(df['valid_accuracy'])) if j == m]
print(max_index, m)
df.loc[max_index]

# 2. Conclusion

knn = KNeighborsClassifier(n_neighbors=22, metric='minkowski', p=3, weights='uniform')
knn.fit(X_train_scale,y_train)
y_test_hat = knn.predict(X_test_scale)
print("test accuracy : ", accuracy_score(y_test, y_test_hat))

\end{lstlisting}
\end{comment}
\end{document}
